
# 一个网页的http请求数应该控制在多少个范围内？
## 问题描述：
网页优化时，我们经常听到的是减少http请求，但是一个大型的网站优化时，当涉及到“文件已不能再优化合并”和“减少http请求数”时，应该如何取舍？还有网页一般http请求需要控制在多少个范围内？
## 分析作答：
首先要说明的是：一个网页的请求数与浏览器无关，与服务器的吞吐量有关，我们需要更多关注的是网页在前2s内的请求数。

1. 网页请求数和服务器吞吐量的关系

假设一个服务器的吞吐量是10万，现1s内有1万page view请求，假设每个page view都不用浏览器缓存，也就是说所有请求都到达服务器，那么为了让网站对所有用户都正常工作，则理论上每个page最多允许10个请求。但是，实际上网站大量的静态资源都用流浪器缓存，所以只有少部分的请求会到达服务器，也就是说用户的两次page view之间，请求数要比理论值少很多。在服务器强大，而便宜，所以很难因为请求数本身一个因素产生伸缩问题。所以关注“总请求数“意义不大。

2. 2s内请求数的扩展说明

2s内的请求数会直接影响到页面的加载速度，和用户的体验密切相关。在这里需要注意的是，每个浏览器的同时并发下载文件的数是有限的，同时能打开的连接数也是有限的。
假设页面2s内要加载24个请求，而浏览器并发下载数是6，那么浏览器需要经过6批次的处理才能全部加载完24个请求，这个请注意，第7个请求会在第一批的某个请求完成后立即执行。又假设浏览器的并发连接数为10个，那么浏览器在10个连接均被占用的情况下，无法再开启新的连接加载下一个文件。这就产生了blocking，会潜在影响用户的体验。

3. 另附各个浏览器的并发请求数

IE 6 and 7:      2
IE 8:            6
IE 9:            6
IE 10:           8
IE 11:           8
Firefox 2:       2
Firefox 3:       6
Firefox 4 to 46: 6
Opera 9.63:      4
Opera 10:        8
Opera 11 and 12: 6
Chrome 1 and 2:  6
Chrome 3:        4
Chrome 4 to 23:  6
Safari 3 and 4:  4

## 扩展
在过去的 HTTP1.1 时代，限制浏览器并发的瓶颈是人为限制的单个连接的并发数。所以那时候才会有域名散列的 CDN 优化方案。但，目前绝大部分用户的浏览器版本都已经支持HTTP2，所以，我们可以大胆地使用链路复用技术请求文件。在HTTP2，用户的页面加载性能瓶颈不再是并发请求的数量限制，而是用户的网络环境。


